{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "model_bleu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Visual Recognition Question 1 IMAGE Captioning"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\n",
        "from numpy import array\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import string\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "from time import time\n",
        "\n",
        "from keras import Input, layers\n",
        "from keras import optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import LSTM, Embedding, Dense, Activation, Flatten, Reshape, Dropout\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.layers.merge import add\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "outputs": [],
      "metadata": {
        "id": "gCuRHztQfL_T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "#drive.mount('/content/drive')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYnRxMAZcALo",
        "outputId": "43e8b2e6-b140-49ac-84cd-17e692c1bfcc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "token_path = \"/content/gdrive/MyDrive/Flickr8k/Flickr8k_text/Flickr8k.lemma.token.txt\"\n",
        "train_images_path = '/content/gdrive/MyDrive/Flickr8k/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "test_images_path = '/content/gdrive/MyDrive/Flickr8k/Flickr8k_text/Flickr_8k.testImages.txt'\n",
        "images_path = '/content/gdrive/MyDrive/Flickr8k/Flicker8k_Images/'\n",
        "glove_path = '/content/gdrive/MyDrive/glove6b'\n",
        "\n",
        "doc = open(token_path,'r').read()\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "qZQSbimgfwOb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "descriptions = dict()\n",
        "for line in doc.split('\\n'):\n",
        "        tokens = line.split()\n",
        "        if len(line) > 2:\n",
        "          image_id = tokens[0].split('.')[0]\n",
        "          image_desc = ' '.join(tokens[1:])\n",
        "          if image_id not in descriptions:\n",
        "              descriptions[image_id] = list()\n",
        "          descriptions[image_id].append(image_desc)"
      ],
      "outputs": [],
      "metadata": {
        "id": "YyXmlDSogqsk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "table = str.maketrans('', '', string.punctuation)\n",
        "for key, desc_list in descriptions.items():\n",
        "    for i in range(len(desc_list)):\n",
        "        desc = desc_list[i]\n",
        "        desc = desc.split()\n",
        "        desc = [word.lower() for word in desc]\n",
        "        desc = [w.translate(table) for w in desc]\n",
        "        desc_list[i] =  ' '.join(desc)"
      ],
      "outputs": [],
      "metadata": {
        "id": "EZSEyjPCgwl5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "vocabulary = set()\n",
        "for key in descriptions.keys():\n",
        "        [vocabulary.update(d.split()) for d in descriptions[key]]\n",
        "print('Original Vocabulary Size: %d' % len(vocabulary))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPjMrcolhEG4",
        "outputId": "c604c00c-0179-4e76-984e-2b52c6672d53"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "lines = list()\n",
        "for key, desc_list in descriptions.items():\n",
        "    for desc in desc_list:\n",
        "        lines.append(key + ' ' + desc)\n",
        "new_descriptions = '\\n'.join(lines)"
      ],
      "outputs": [],
      "metadata": {
        "id": "e7L5zKbOhLR4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "doc = open(train_images_path,'r').read()\n",
        "dataset = list()\n",
        "for line in doc.split('\\n'):\n",
        "    if len(line) > 1:\n",
        "      identifier = line.split('.')[0]\n",
        "      dataset.append(identifier)\n",
        "\n",
        "train = set(dataset)"
      ],
      "outputs": [],
      "metadata": {
        "id": "fK1tA3UMhMUg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "doc = open(test_images_path,'r').read()\n",
        "dataset = list()\n",
        "for line in doc.split('\\n'):\n",
        "    if len(line) > 1:\n",
        "      identifier = line.split('.')[0]\n",
        "      dataset.append(identifier)\n",
        "\n",
        "test = set(dataset)"
      ],
      "outputs": [],
      "metadata": {
        "id": "6hFH7j22XgSA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpFaQqOlYCUR",
        "outputId": "ccaba8bb-c634-4203-ef01-cc0a13f3d88f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "img = glob.glob(images_path + '*.jpg')\n",
        "print(img)\n",
        "train_images = set(open(train_images_path, 'r').read().strip().split('\\n'))\n",
        "train_img = []\n",
        "for i in img: \n",
        "    if i[len(images_path):] in train_images:\n",
        "        train_img.append(i)\n",
        "\n",
        "test_images = set(open(test_images_path, 'r').read().strip().split('\\n'))\n",
        "test_img = []\n",
        "for i in img: \n",
        "    if i[len(images_path):] in test_images: \n",
        "        test_img.append(i)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "m5sdS9syhPel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5b78283-22c2-4130-de76-2416b5e9190c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_descriptions = dict()\n",
        "for line in new_descriptions.split('\\n'):\n",
        "    tokens = line.split()\n",
        "    image_id, image_desc = tokens[0], tokens[1:]\n",
        "    if image_id in train:\n",
        "        if image_id not in train_descriptions:\n",
        "            train_descriptions[image_id] = list()\n",
        "        desc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
        "        train_descriptions[image_id].append(desc)"
      ],
      "outputs": [],
      "metadata": {
        "id": "d72HQjNFhSut"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test_descriptions = dict()\n",
        "for line in new_descriptions.split('\\n'):\n",
        "    tokens = line.split()\n",
        "    image_id, image_desc = tokens[0], tokens[1:]\n",
        "    if image_id in test:\n",
        "        if image_id not in test_descriptions:\n",
        "            test_descriptions[image_id] = list()\n",
        "        desc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
        "        test_descriptions[image_id].append(desc)"
      ],
      "outputs": [],
      "metadata": {
        "id": "iMAlA-_XXnTO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "all_train_captions = []\n",
        "for key, val in train_descriptions.items():\n",
        "    for cap in val:\n",
        "        all_train_captions.append(cap)"
      ],
      "outputs": [],
      "metadata": {
        "id": "8ajdrz9ghXXw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "word_count_threshold = 10\n",
        "word_counts = {}\n",
        "nsents = 0\n",
        "for sent in all_train_captions:\n",
        "    nsents += 1\n",
        "    for w in sent.split(' '):\n",
        "        word_counts[w] = word_counts.get(w, 0) + 1\n",
        "vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
        "\n",
        "print('Vocabulary = %d' % (len(vocab)))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mDfAnddhait",
        "outputId": "9eccf7a7-e051-441d-eb95-27ec97d07971"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ixtoword = {}\n",
        "wordtoix = {}\n",
        "ix = 1\n",
        "for w in vocab:\n",
        "    wordtoix[w] = ix\n",
        "    ixtoword[ix] = w\n",
        "    ix += 1\n",
        "\n",
        "vocab_size = len(ixtoword) + 1"
      ],
      "outputs": [],
      "metadata": {
        "id": "K1Ie6ssShh6V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "all_desc = list()\n",
        "for key in train_descriptions.keys():\n",
        "    [all_desc.append(d) for d in train_descriptions[key]]\n",
        "lines = all_desc\n",
        "max_length = max(len(d.split()) for d in lines)\n",
        "\n",
        "print('Description Length: %d' % max_length)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tPagXU_hi3u",
        "outputId": "7488765e-bb91-4246-c3dc-989e74dfe880"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "embeddings_index = {} \n",
        "f = open(os.path.join(glove_path, 'glove.6B.200d.txt'), encoding=\"utf-8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs"
      ],
      "outputs": [],
      "metadata": {
        "id": "jSWJEi0vhlVA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "embedding_dim = 200\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in wordtoix.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "outputs": [],
      "metadata": {
        "id": "wDlbJDrWh1MC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = InceptionV3(weights='imagenet')"
      ],
      "outputs": [],
      "metadata": {
        "id": "iUu1DarSh4Gw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model_new = Model(model.input, model.layers[-2].output)"
      ],
      "outputs": [],
      "metadata": {
        "id": "O2-VsKpWh9pt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def preprocess(image_path):\n",
        "    img = image.load_img(image_path, target_size=(299, 299))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    return x"
      ],
      "outputs": [],
      "metadata": {
        "id": "kYLiEh0ViCzF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def encode(image):\n",
        "    image = preprocess(image) \n",
        "    fea_vec = model_new.predict(image) \n",
        "    fea_vec = np.reshape(fea_vec, fea_vec.shape[1])\n",
        "    return fea_vec\n",
        "\n",
        "#encoding_train = {}\n",
        "#for img in train_img:\n",
        " #   encoding_train[img[len(images_path):]] = encode(img)\n",
        "#train_features = encoding_train\n",
        "\n",
        "#encoding_test = {}\n",
        "#for img in test_img:\n",
        " #   encoding_test[img[len(images_path):]] = encode(img)"
      ],
      "outputs": [],
      "metadata": {
        "id": "8adC6oLNiFcQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pickle\n",
        "\n",
        "#with open('/content/gdrive/My Drive/train_encoding.pkl', 'wb') as handle:\n",
        " #   pickle.dump(encoding_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "#with open('/content/gdrive/My Drive/test_encoding.pkl', 'wb') as handle:\n",
        " #   pickle.dump(encoding_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "encoding_train = {}\n",
        "encoding_test = {}\n",
        "\n",
        "import pickle #credits to stack overflow user= blender\n",
        "\n",
        "with open('/content/gdrive/My Drive/train_encoding.pkl', 'rb') as handle:\n",
        "   encoding_train = pickle.load(handle)\n",
        "\n",
        "with open('/content/gdrive/My Drive/test_encoding.pkl', 'rb') as handle:\n",
        "    encoding_test = pickle.load(handle)"
      ],
      "outputs": [],
      "metadata": {
        "id": "X34v_vayP0-G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "inputs1 = Input(shape=(2048,))\n",
        "fe1 = Dropout(0.5)(inputs1)\n",
        "fe2 = Dense(256, activation='relu')(fe1)\n",
        "\n",
        "inputs2 = Input(shape=(max_length,))\n",
        "se1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\n",
        "se2 = Dropout(0.5)(se1)\n",
        "se3 = LSTM(256)(se2)\n",
        "\n",
        "decoder1 = add([fe2, se3])\n",
        "decoder2 = Dense(256, activation='relu')(decoder1)\n",
        "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "\n",
        "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "model.summary()"
      ],
      "outputs": [],
      "metadata": {
        "id": "JWf6uH-oiKfR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d37106-35c1-4dd4-d19f-c7512c074b86"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.layers[2].set_weights([embedding_matrix])\n",
        "model.layers[2].trainable = False"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZioOkj8HiSNE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "outputs": [],
      "metadata": {
        "id": "2VYhM4-1iT9u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def data_generator(descriptions, photos, wordtoix, max_length, num_photos_per_batch):\n",
        "    X1, X2, y = list(), list(), list()\n",
        "    n=0\n",
        "    #print(photos)\n",
        "    #print(descriptions)\n",
        "    # loop for ever over images\n",
        "    while 1:\n",
        "        for key, desc_list in descriptions.items():\n",
        "            #print(key)\n",
        "            #print(desc_list)\n",
        "            n+=1\n",
        "            # retrieve the photo feature\n",
        "            photo = photos[key+'.jpg']\n",
        "            for desc in desc_list:\n",
        "                # encode the sequence\n",
        "                seq = [wordtoix[word] for word in desc.split(' ') if word in wordtoix]\n",
        "                # split one sequence into multiple X, y pairs\n",
        "                for i in range(1, len(seq)):\n",
        "                    # split into input and output pair\n",
        "                    in_seq, out_seq = seq[:i], seq[i]\n",
        "                    # pad input sequence\n",
        "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "                    # encode output sequence\n",
        "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "                    # store\n",
        "                    X1.append(photo)\n",
        "                    X2.append(in_seq)\n",
        "                    y.append(out_seq)\n",
        "\n",
        "            if n==num_photos_per_batch:\n",
        "                yield ([array(X1), array(X2)], array(y))\n",
        "                X1, X2, y = list(), list(), list()\n",
        "                n=0"
      ],
      "outputs": [],
      "metadata": {
        "id": "VTgPxDE4iaAL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "epochs = 25\n",
        "batch_size = 3\n",
        "steps = len(train_descriptions)//batch_size\n",
        "\n",
        "#generator = data_generator(train_descriptions, train_features, wordtoix, max_length, batch_size)\n",
        "#model.fit(generator, epochs=epochs, steps_per_epoch=steps, verbose=1)\n",
        "\n",
        "model.load_weights('/content/gdrive/My Drive/mymodel.h5')"
      ],
      "outputs": [],
      "metadata": {
        "id": "5x2P0C3wieiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebdeb3c7-39fa-4bcc-8dca-32a546ab9aa3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.save_weights('/content/mymodel.h5')"
      ],
      "outputs": [],
      "metadata": {
        "id": "B7qlOp31jDd4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "mekeHHmljDlW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def greedySearch(photo):\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = [wordtoix[w] for w in in_text.split() if w in wordtoix]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = model.predict([photo,sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = ixtoword[yhat]\n",
        "        in_text += ' ' + word\n",
        "        if word == 'endseq':\n",
        "            break\n",
        "\n",
        "    final = in_text.split()\n",
        "    final = final[1:-1]\n",
        "    final = ' '.join(final)\n",
        "    return final"
      ],
      "outputs": [],
      "metadata": {
        "id": "x4DgGqezjDvx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def beam_search_predictions(image, beam_index = 3):\n",
        "    start = [wordtoix[\"startseq\"]]\n",
        "    start_word = [[start, 0.0]]\n",
        "    while len(start_word[0][0]) < max_length:\n",
        "        temp = []\n",
        "        for s in start_word:\n",
        "            par_caps = sequence.pad_sequences([s[0]], maxlen=max_length, padding='post')\n",
        "            preds = model.predict([image,par_caps], verbose=0)\n",
        "            word_preds = np.argsort(preds[0])[-beam_index:]\n",
        "            # Getting the top <beam_index>(n) predictions and creating a \n",
        "            # new list so as to put them via the model again\n",
        "            for w in word_preds:\n",
        "                next_cap, prob = s[0][:], s[1]\n",
        "                next_cap.append(w)\n",
        "                prob += preds[0][w]\n",
        "                temp.append([next_cap, prob])\n",
        "                    \n",
        "        start_word = temp\n",
        "        # Sorting according to the probabilities\n",
        "        start_word = sorted(start_word, reverse=False, key=lambda l: l[1])\n",
        "        # Getting the top words\n",
        "        start_word = start_word[-beam_index:]\n",
        "    \n",
        "    start_word = start_word[-1][0]\n",
        "    intermediate_caption = [ixtoword[i] for i in start_word]\n",
        "    final_caption = []\n",
        "    \n",
        "    for i in intermediate_caption:\n",
        "        if i != 'endseq':\n",
        "            final_caption.append(i)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    final_caption = ' '.join(final_caption[1:])\n",
        "    return final_caption"
      ],
      "outputs": [],
      "metadata": {
        "id": "4EYx4QYpjHmx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pic = '2398605966_1d0c9e6a20.jpg'\n",
        "image = encoding_test[pic].reshape((1,2048))\n",
        "x=plt.imread(images_path+pic)\n",
        "plt.imshow(x)\n",
        "plt.show()\n",
        "\n",
        "print(\"Greedy Search:\",greedySearch(image))\n",
        "print(\"Beam Search, K = 3:\",beam_search_predictions(image, beam_index = 3))\n",
        "print(\"Beam Search, K = 5:\",beam_search_predictions(image, beam_index = 5))\n",
        "print(\"Beam Search, K = 7:\",beam_search_predictions(image, beam_index = 7))\n",
        "print(\"Beam Search, K = 10:\",beam_search_predictions(image, beam_index = 10))\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "bl = 0\n",
        "for p in test:\n",
        "  image = p+'.jpg'\n",
        "  image = encoding_test[pic].reshape((1,2048))\n",
        "  r = test_descriptions[p]\n",
        "  d = beam_search_predictions(image, beam_index = 3)\n",
        "  score = sentence_bleu(r, d)\n",
        "  bl = bl+score\n",
        "  print(score)\n",
        "\n",
        "\n",
        "bleu = bl/1000\n",
        "print(bleu)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "Dvg27_CJjKEQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "bl = 0\n",
        "i = 0\n",
        "for p in test:\n",
        "  i = i+1\n",
        "  image = p+'.jpg'\n",
        "  image = encoding_test[pic].reshape((1,2048))\n",
        "  r = test_descriptions[p]\n",
        "  d = beam_search_predictions(image, beam_index = 5)\n",
        "  score = sentence_bleu(r, d)\n",
        "  bl = bl+score\n",
        "  print(i,score)\n",
        "\n",
        "\n",
        "bleu = bl/1000\n",
        "print(i,bleu)"
      ],
      "outputs": [],
      "metadata": {
        "id": "HFLk-KxKrhTb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "bl = 0\n",
        "for p in test:\n",
        "  image = p+'.jpg'\n",
        "  image = encoding_test[pic].reshape((1,2048))\n",
        "  r = test_descriptions[p]\n",
        "  d = beam_search_predictions(image, beam_index = 7)\n",
        "  score = sentence_bleu(r, d)\n",
        "  bl = bl+score\n",
        "  print(score)\n",
        "\n",
        "\n",
        "bleu = bl/1000\n",
        "print('Bleu score is'+bleu)"
      ],
      "outputs": [],
      "metadata": {
        "id": "VU6uHaETrkoM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "bl = 0\n",
        "for p in test:\n",
        "  image = p+'.jpg'\n",
        "  image = encoding_test[pic].reshape((1,2048))\n",
        "  r = test_descriptions[p]\n",
        "  d = greedySearch(image)\n",
        "  score = sentence_bleu(r, d)\n",
        "  bl = bl+score\n",
        "  print(score)\n",
        "\n",
        "\n",
        "bleu = bl/1000\n",
        "print(\"Bleu score:\",bleu)"
      ],
      "outputs": [],
      "metadata": {
        "id": "lOqNjVXTrnc2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "AvC_earqYdT8"
      }
    }
  ]
}